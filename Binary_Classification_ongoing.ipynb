{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import required packages \n",
    "from __future__ import division, print_function # Imports from __future__ since we're running Python 2\n",
    "import os\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "random_state=0\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "rng = np.random.RandomState(seed=random_state)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_data = os.path.join(os.getcwd(),'train_data_ongoing.csv')\n",
    "flights_train = pd.read_csv(path_data, delimiter = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_data = os.path.join(os.getcwd(),'test_data_ongoing.csv')\n",
    "flights_test = pd.read_csv(path_data, delimiter = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "flights_train.loc[flights_train['ARR_DELAY_GROUP'] > 0, 'ARR_DELAY_GROUP'] = 1\n",
    "flights_test.loc[flights_test['ARR_DELAY_GROUP'] > 0, 'ARR_DELAY_GROUP'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_full = flights_train.drop('ARR_DELAY_GROUP', axis=1).values.astype(np.float) # Training features\n",
    "y_train_full = flights_train['ARR_DELAY_GROUP'].values # Training labels\n",
    "X_test = flights_test.drop('ARR_DELAY_GROUP', axis=1).values.astype(np.float) # Training features\n",
    "y_test = flights_test['ARR_DELAY_GROUP'].values # Training labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, \n",
    "                                                  test_size=0.2, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sc = StandardScaler().fit(X_train)\n",
    "X_train_sc = sc.transform(X_train)\n",
    "X_val_sc = sc.transform(X_val)\n",
    "X_test_sc = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification performance on validation set:\n",
      "Logistic Regression, accuracy: 0.828, log-loss: 0.381, kappa score: 0.625\n",
      "Nearest Neighbors, accuracy: 0.730, log-loss: 0.570, kappa score: 0.403\n",
      "Decision Tree, accuracy: 0.823, log-loss: 0.642, kappa score: 0.601\n",
      "Random Forest, accuracy: 0.817, log-loss: 0.433, kappa score: 0.582\n",
      "Naive Bayes, accuracy: 0.634, log-loss: 12.455, kappa score: 0.349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chris\\Anaconda3\\envs\\mlp\\lib\\site-packages\\sklearn\\discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA, accuracy: 0.827, log-loss: 0.392, kappa score: 0.621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chris\\Anaconda3\\envs\\mlp\\lib\\site-packages\\sklearn\\discriminant_analysis.py:695: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QDA, accuracy: 0.659, log-loss: 11.561, kappa score: 0.261\n",
      "Neural Net (Multi-layer perceptron), accuracy: 0.821, log-loss: 0.716, kappa score: 0.599\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.stats import mode # Computes the mode of a signal\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import cohen_kappa_score, make_scorer\n",
    "kappa_scorer = make_scorer(cohen_kappa_score)\n",
    "names = [\"Logistic Regression\", \"Nearest Neighbors\",\n",
    "         \"Decision Tree\", \"Random Forest\", \n",
    "         \"Naive Bayes\", \"LDA\", \"QDA\",\"Neural Net (Multi-layer perceptron)\"]\n",
    "classifiers = [\n",
    "    LogisticRegression(solver='lbfgs', multi_class='multinomial'),\n",
    "    KNeighborsClassifier(n_neighbors=10),\n",
    "    DecisionTreeClassifier(max_depth=10),\n",
    "    RandomForestClassifier(max_depth=10, n_estimators=50,random_state=random_state),\n",
    "    GaussianNB(),\n",
    "    LinearDiscriminantAnalysis(),\n",
    "    QuadraticDiscriminantAnalysis(),\n",
    "    MLPClassifier(random_state=random_state)]\n",
    "ca_score = {} # Classification accuracy\n",
    "ce_score = {} # Cross-entropy\n",
    "kc_score = {} #kappa score\n",
    "print('Classification performance on validation set:')\n",
    "for name, clf in zip(names, classifiers):\n",
    "    clf.fit(X_train_sc, y_train)\n",
    "    ca_score[name] = clf.score(X_val_sc, y_val)\n",
    "    ce_score[name] = log_loss(y_val, clf.predict_proba(X_val_sc))\n",
    "    kc_score[name] = cohen_kappa_score(y_val,clf.predict(X_val_sc))\n",
    "    print (\"{}, accuracy: {:.3f}, log-loss: {:.3f}, kappa score: {:.3f}\".format(name, ca_score[name], ce_score[name], kc_score[name]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best setting of C parameter for Logistic Regression: 0.1\n",
      "Best cross-validated score: 0.831\n",
      "Classification accuracy on validation set: 0.828\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "cv = KFold(n_splits=3, shuffle=True, random_state=random_state)\n",
    "svc = LogisticRegression(penalty='l2'\n",
    "        ,fit_intercept=True\n",
    "        ,solver='newton-cg'\n",
    "        ,multi_class='multinomial'\n",
    "        ,max_iter=4000)\n",
    "parameters = {'C': np.logspace(-3,3,7)}\n",
    "svc_clf = GridSearchCV(estimator=svc, cv=cv, param_grid=parameters, scoring='accuracy')\n",
    "svc_clf.fit(X_train_sc, y_train)\n",
    "print(\"Best setting of C parameter for Logistic Regression: {}\".format(svc_clf.best_params_[\"C\"]))\n",
    "print(\"Best cross-validated score: {:.3f}\".\n",
    "      format(svc_clf.best_score_))\n",
    "print(\"Classification accuracy on validation set: {:.3f}\".format(svc_clf.score(X_val_sc,y_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification performance on validation set:\n",
      "Validation Logistic Regression, accuracy: 0.828, log-loss: 0.385, kappa score: 0.626\n",
      "Validation Logistic Regression,precision: 0.805, recall: 0.825, f1: 0.831\n",
      "Test Logistic Regression, accuracy: 0.832, log-loss: 0.378, kappa score: 0.633\n",
      "Test Logistic Regression,precision: 0.809, recall: 0.828, f1: 0.835\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "kappa_scorer = make_scorer(cohen_kappa_score)\n",
    "names = [\"Logistic Regression\"]\n",
    "classifiers = [LogisticRegression(penalty='l2'\n",
    "        ,C=0.1\n",
    "        ,fit_intercept=True\n",
    "        ,solver='newton-cg'\n",
    "        ,multi_class='multinomial'\n",
    "        ,max_iter=4000)]\n",
    "ca_score = {} # Classification accuracy\n",
    "ce_score = {} # Cross-entropy\n",
    "kc_score = {} #kappa score\n",
    "print('Classification performance on validation set:')\n",
    "for name, clf in zip(names, classifiers):\n",
    "    clf.fit(X_train_sc, y_train)\n",
    "    ca_score[name] = clf.score(X_val_sc, y_val)\n",
    "    ce_score[name] = log_loss(y_val, clf.predict_proba(X_val_sc))\n",
    "    kc_score[name] = cohen_kappa_score(y_val,clf.predict(X_val_sc))\n",
    "    precision =  metrics.precision_score(y_val, clf.predict(X_val_sc), average='macro') \n",
    "    recall = metrics.recall_score(y_val, clf.predict(X_val_sc), average='macro')\n",
    "    f1 =  metrics.f1_score(y_val, clf.predict(X_val_sc), average='weighted')\n",
    "    print (\"Validation {}, accuracy: {:.3f}, log-loss: {:.3f}, kappa score: {:.3f}\".format(name, ca_score[name], ce_score[name], kc_score[name]))\n",
    "    print (\"Validation {},precision: {:.3f}, recall: {:.3f}, f1: {:.3f}\".format(name, precision,recall,f1))\n",
    "    test1 = clf.score(X_test_sc, y_test)\n",
    "    test2 = log_loss(y_test, clf.predict_proba(X_test_sc))\n",
    "    test3 = cohen_kappa_score(y_test,clf.predict(X_test_sc))\n",
    "    print (\"Test {}, accuracy: {:.3f}, log-loss: {:.3f}, kappa score: {:.3f}\".format(name, test1, test2, test3))\n",
    "    precision =  metrics.precision_score(y_test,clf.predict(X_test_sc), average='macro') \n",
    "    recall = metrics.recall_score(y_test,clf.predict(X_test_sc), average='macro')\n",
    "    f1 =  metrics.f1_score(y_test,clf.predict(X_test_sc), average='weighted')\n",
    "    print (\"Test {},precision: {:.3f}, recall: {:.3f}, f1: {:.3f}\".format(name, precision,recall,f1))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
